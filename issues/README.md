## æ¨¡å‹è®­ç»ƒè®°å½•QA

### 1 åœ¨gogptåº•åº§å¾®è°ƒï¼ˆsftï¼‰é˜¶æ®µï¼Œå‡ºç°å­¦ä¹ ç‡ä¸º0
å­¦ä¹ ç‡æ…¢æ…¢å˜ä¸º0ï¼Œä¸€å¼€å§‹è¿˜æ˜¯æ­£å¸¸çš„å­¦ä¹ é¢„çƒ­+è¡°å‡ï¼Œä½†æ˜¯åˆ°åæœŸï¼ˆæ¯”å¦‚è¿­ä»£2000æ­¥ï¼‰ä¹‹åï¼Œå­¦ä¹ ç‡ç›´æ¥å˜ä¸º0äº†ã€‚
```text
gradient_accumulation_stepsè®¾ç½®ä¸º1

åœ¨Github Issuesçœ‹åˆ°ä¹Ÿå’Œdeepspeedçš„å­¦ä¹ ç‡è§„åˆ’å™¨è®¾ç½®å†²çªäº†ï¼Œå»é™¤deepspeedä¸­å…³äºä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è§„åˆ’å™¨çš„è®¾ç½®å³å¯
```
![issue1.png](assets%2Fissue1.png)

### 2 åœ¨gogptåº•åº§å¾®è°ƒï¼ˆsftï¼‰é˜¶æ®µï¼Œå‡ºç°lossä¸º0
![img.png](assets/issue2.png)
ï¼ˆ1ï¼‰å’Œæ•°æ®é›†æœ‰å…³ç³»,å’Œæ•°æ®é›†è¿™ä¸ªéœ€è¦æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ³„éœ²ï¼Œlossä¸º0ä¹Ÿæ˜¯æ­£å¸¸çš„
ï¼ˆ2ï¼‰å’Œç´¯è®¡æ¢¯åº¦å¤§å°æœ‰å…³ç³»ï¼Œè®¾ç½®ä¸º1ï¼›å’Œç²¾åº¦æœ‰å…³ç³»ï¼Œä¸ç”¨float16
### 3 æŒ‡ä»¤å¾®è°ƒçš„æ—¶å€™æ¨¡æ¿åº”è¯¥æ€ä¹ˆè®¾è®¡ï¼Ÿä¸ç”¨æ¨¡æ¿å¯ä»¥å—ï¼Ÿ

å¸¸è§çš„æ˜¯stanford_alpacaä¸­æ¨¡æ¿ï¼š
```text
PROMPT_DICT = {
    "prompt_input": (
        "Below is an instruction that describes a task, paired with an input that provides further context. "
        "Write a response that appropriately completes the request.\n\n"
        "### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:"
    ),
    "prompt_no_input": (
        "Below is an instruction that describes a task. "
        "Write a response that appropriately completes the request.\n\n"
        "### Instruction:\n{instruction}\n\n### Response:"
    ),
}
```


Llama2ä¸­çš„æ¨¡æ¿
```text
instruction = """[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

            If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n\n{} [/INST]"""

```

Linly-AIä¸­æ¨¡æ¿
```text
### Instruction:{prompt.strip()}  ### Response:
```

NousResearch

```text
### Instruction:
<prompt>

### Response:
<leave a newline blank for model to respond>
```

```text
### Instruction:
<prompt>

### Input:
<additional context>

### Response:
<leave a newline blank for model to respond>

```

Yayi
> https://huggingface.co/wenge-research/yayi-7b-llama2
> 
```text
prompt = "ä½ æ˜¯è°ï¼Ÿ"
formatted_prompt = f"""<|System|>:
You are a helpful, respectful and honest assistant named YaYi developed by Beijing Wenge Technology Co.,Ltd. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.

<|Human|>:
{prompt}

<|YaYi|>:
"""
```

StableBeluga2
> https://huggingface.co/stabilityai/StableBeluga2
```text
### System:
This is a system prompt, please behave and help the user.

### User:
Your prompt here

### Assistant:
The output of Stable Beluga 2
```
æ¯”å¦‚
```text
system_prompt = "### System:\nYou are Stable Beluga, an AI that follows instructions extremely well. Help as much as you can. Remember, be safe, and don't do anything illegal.\n\n"

message = "Write me a poem please"
prompt = f"{system_prompt}### User: {message}\n\n### Assistant:\n"
```


llama-2-70b-Guanaco-QLoRA-fp16
```text
### Human: {prompt}
### Assistant:
```

```text
prompt = "Introduce yourself"
formatted_prompt = (
    f"A chat between a curious human and an artificial intelligence assistant."
    f"The assistant gives helpful, detailed, and polite answers to the user's questions.\n"
    f"### Human: {prompt} ### Assistant:"
)
```

### 4 å¤šè½®å¯¹è¯æ•°æ®æ€ä¹ˆæ„é€ 
- æ–¹å¼1ï¼šè®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬å°†å¤šè½®å¯¹è¯æ‹¼æ¥æˆå¦‚ä¸‹æ ¼å¼ï¼Œç„¶åè¿›è¡Œtokenizeã€‚å…¶ä¸­<s>è¡¨ç¤ºbos_tokenï¼Œ</s> è¡¨ç¤ºeos_tokenã€‚
```text
<s>input1</s>target1</s>input2</s>target2</s>...
```
> https://github.com/yangjianxin1/Firefly

åœ¨è®¡ç®—lossæ—¶ï¼Œæˆ‘ä»¬é€šè¿‡maskçš„æ–¹å¼ï¼Œinputéƒ¨åˆ†çš„lossä¸å‚ä¸å‚æ•°æ›´æ–°ï¼Œåªæœ‰â€œtargetâ€éƒ¨åˆ†çš„losså‚ä¸å‚æ•°æ›´æ–°ã€‚ è¿™ç§æ–¹å¼å……åˆ†åˆ©ç”¨äº†æ¨¡å‹å¹¶è¡Œè®¡ç®—çš„ä¼˜åŠ¿ï¼Œè®­ç»ƒæ›´åŠ é«˜æ•ˆï¼Œä¸”å¤šè½®å¯¹è¯ä¸­çš„æ¯ä¸ªtargetéƒ¨åˆ†éƒ½å‚ä¸äº†è®­ç»ƒï¼Œè®­ç»ƒæ›´å……åˆ†ã€‚ å¦åˆ™ï¼Œå°±éœ€è¦æŠŠä¸€ä¸ªnè½®å¯¹è¯ï¼Œæ‹†åˆ†æˆnæ¡æ•°æ®ï¼Œä¸”åªè®¡ç®—æœ€åä¸€ä¸ªtargetçš„lossï¼Œå¤§å¤§é™ä½äº†è®­ç»ƒæ•ˆç‡ã€‚


### 5 Bugs:FAILED: multi_tensor_adam.cuda.o 

```text
åŸå› ï¼šCUDAç¯å¢ƒå˜é‡æ²¡æœ‰é…ç½®æ­£ç¡®ï¼š
/bin/sh: /usr/usr/local/cuda-12.2/bin/nvcc: No such file or directory
```
æ”¹æˆ`/usr/local/cuda-12.2/bin/nvcc`å³å¯

æ­£ç¡®é…ç½®å¦‚ä¸‹
```text
export PATH=/usr/local/cuda-12.2/bin:$PATH  
export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64:$LD_LIBRARY_PATH
export CUDA_HOME=/usr/local/cuda-12.2/
```

### 6 å¸¸è§è‹±æ–‡å¾®è°ƒæ•°æ®é›†æœ‰å“ªäº›
```text
1ã€ æ¨¡å‹1 https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b


GPTeacher was made available by Teknium
https://huggingface.co/datasets/teknium/GPTeacher-General-Instruct

Wizard LM by nlpxucan
https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k


Nous Research Instruct Dataset was provided by Karan4D and HueminArt.




GPT4-LLM and Unnatural Instructions were provided by Microsoft
https://huggingface.co/datasets/teknium/GPT4-LLM-Cleaned?clone=true

Airoboros dataset by jondurbin
https://huggingface.co/datasets/jondurbin/airoboros-gpt4-m2.0?clone=true


Camel-AI's domain expert datasets are from Camel-AI
CodeAlpaca dataset by Sahil 2801.



2ã€æ¨¡å‹2 https://huggingface.co/stabilityai/StableBeluga2


/home/searchgpt/pretrained_models/data/WizardLM_evol_instruct_V2_143k/WizardLM_evol_instruct_V2_143k.jsonl


/home/searchgpt/pretrained_models/gogpt2-7b

/home/searchgpt/yq/Firefly/output/firefly-llama2-7b/final


/home/searchgpt/yq/Firefly/checkpoint/gogpt2-7b-qlora-sft-merge

Run "huggingface-cli lfs-enable-largefiles ./path/to/your/repo" and try again.
Run "huggingface-cli lfs-enable-largefiles ./path/to/your/repo" and try again.


/data/searchgpt/yq/GoGPT/outputs-pt-v1-13b-llama2
```

### 7 NCCLé€šä¿¡è¶…æ—¶
```text
[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=11455, OpType=BROADCAST, Timeout(ms)=1800000)
 ran for 1806422 mi
```
![img.png](assets/issue7.png)

è§£å†³æ–¹æ¡ˆï¼š
```text
æŠŠtimeoutæ”¹å¤§ or ä¿®æ”¹ä¸ºstreaming datasetsæ–¹å¼
```

### 8 æŒ‡ä»¤æ•°æ®é›†æ€ä¹ˆé…æ¯”ï¼Ÿ
ä¸­æ–‡å°½é‡å‡è¡¡ 1:1ï¼Œä»»åŠ¡å¤šæ ·æ€§
![img.png](assets/issue8.png)

### 9 RuntimeError: CUDA error: uncorrectable ECC error encountered 

æ˜¾å¡é•¿æ—¶é—´è¿è¡Œï¼Œå¯èƒ½ä¼šæœ‰äº›ç‰©ç†æ•…éšœ
```text
RuntimeError: CUDA error: uncorrectable ECC error encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertio
```
![img.png](assets/issue9.png)

### 10 å¤§æ¨¡å‹å¾®è°ƒæœ‰å“ªäº›ç»éªŒ
ç¨å¾®æ€»ç»“ä¸‹å¾®è°ƒçš„æ€è·¯ï¼Œè¯·æŒ‰é¡ºåºçœ‹ï¼š
- ï¼ˆ1ï¼‰ğŸš©æ•°æ®é›†å°½é‡å¤šæ ·æ€§ï¼Œé¿å…è·‘å®Œä¹‹åå†è·‘ï¼ˆè¿™ä¸ªè¿˜æ²¡éªŒè¯è¿‡å¤šæ¬¡å åŠ å¾®è°ƒæ˜¯å¦æœ‰å½±å“ï¼Œä½†æ˜¯ä¸å¦‚å®Œæ•´çš„è·‘å®Œæ¯”è¾ƒé è°±ï¼‰ï¼Œæ‰€ä»¥æ¯æ¬¡å¾®è°ƒä¹‹å‰ï¼Œä¸è¦ç€æ€¥ï¼ï¼Œè¦æƒ³å¥½è¿™æ¬¡è·‘çš„ç›®çš„æ˜¯ä¸ºäº†ä»€ä¹ˆï¼Œå°½é‡æŠŠæ€è·¯æ¢³ç†æ¸…æ¥šï¼Œæ•°æ®é›†å‡†å¤‡å¥½ï¼Œé¿å…æ¥å›æŠ˜è…¾
- ï¼ˆ2ï¼‰ğŸš©æ•°æ®é›†å¯èƒ½éœ€è¦è¿‡æ»¤çš„åœ°æ–¹ï¼šï¼ˆaï¼‰è¯­è¨€ï¼Œæ˜¯å¦é™¤äº†ä¸­è‹±æ–‡è¿˜åŒ…å«å…¶ä»–è¯­è¨€ï¼ˆbï¼‰é•¿åº¦ï¼Œä¸ªäººè®¤ä¸ºå°½é‡è®­ç»ƒæ•°æ®é€‰æ‹©é•¿ä¸€ç‚¹çš„æ¯”è¾ƒå¥½ï¼Œè¿™æ ·æµ‹è¯•çš„æ—¶å€™ç”Ÿæˆæ•ˆæœç›´è§‚ä¸Šæ˜¯â€œæŒºä¸é”™çš„â€(c) ä¸­è‹±æ–‡é…æ¯”ï¼šå°½é‡ä¸è¦åªåŠ ä¸­æ–‡æˆ–è€…è‹±æ–‡ï¼Œå¦‚æœä¸­æ–‡èƒ½åŠ›å¼±ï¼Œå¯ä»¥å°½é‡ä½¿ç”¨å¤šä¸€ç‚¹ä¸­æ–‡ï¼Œç„¶åé…æ¯”ä¸€äº›è‹±æ–‡æ•°æ®ï¼Œå¯ä»¥æ¿€å‘æ¨¡å‹çš„ä¸­æ–‡å¯¹é½çš„æ•ˆæœã€‚ï¼ˆdï¼‰è¿˜æœ‰äº‹å…ˆæœ€å¥½æ£€æŸ¥ä¸‹å¾®è°ƒæ•°æ®é›†ä¸­æ˜¯å¦å­˜åœ¨å–ç‚¹æ•°æ®ï¼Œæ¯”å¦‚æ•°æ®é›†é‡Œé¢å­˜åœ¨ï¼Œæˆ‘æ˜¯GPT4åŠ©æ‰‹ã€MOSSåŠ©æ‰‹ï¼Œå…¶å®ä½ è¦æƒ³è¦çš„æ˜¯ä½ åŠ©æ‰‹çš„åå­—ã€‚
- ï¼ˆ3ï¼‰ğŸš©æ•°æ®é›†é€‰æ‹©ï¼šä»ä¸€äº›é¡¹ç›®å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ä¸æ‰©å……è¯è¡¨çš„æƒ…å†µä¸‹ï¼Œæ•°æ®é‡å¤§ä¹Ÿå¯ä»¥å‡ºå¥‡è¿¹ï¼Œä½†æ˜¯ä¸æ‰©å……è¯è¡¨çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹åœ¨æ¨ç†ä½¿ç”¨çš„æ—¶å€™ä¸Šä¸‹æ–‡èƒ½åŠ›æ˜¯é¦–å…ˆçš„ï¼Œä¹‹å‰åœ¨ã€Šhow-to-train-tokenizerã€‹é‡Œé¢åˆ†æè¿‡ï¼Œæ‰©å……è¯è¡¨ä¹‹ååˆ†è¯æ•ˆç‡ç‰¹åˆ«é«˜ï¼ˆæ¯”å¦‚ä¹‹å‰æ¥å—1000ä¸­æ–‡å­—ç¬¦ï¼Œå¯èƒ½ç°åœ¨å¯ä»¥æ¥å—4000ä¸­æ–‡å­—ç¬¦ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥é‡‡ç”¨å¤šæ ·æ€§çš„æ•°æ®é›†è¿›æ¥ï¼Œæ¯”å¦‚å¤šè½®å¯¹è¯ã€alpacaæŒ‡ä»¤æ•°æ®ã€ç¤¾åŒºé—®ç­”ã€è§’è‰²æ‰®æ¼”ã€gpt4ç­‰ç­‰ã€‚
- ï¼ˆ4ï¼‰ğŸš©å…³äºç¬¬ä¸€æ¡ï¼ŒéªŒè¯è¿‡ï¼Œç°åœ¨100å¤šä¸‡æ•°æ®ä¸æ˜¯mossçš„å—ï¼Œé‡Œé¢æœ‰â€œMOSS xxxçš„â€åŸ‹ç‚¹æ•°æ®ï¼Œç„¶åç°åœ¨é€šè¿‡Loraä¿®æ­£äº†æ¨¡å‹ï¼Œå¯ä»¥å›å¤â€œGoGPTåŠ©æ‰‹äº†â€ï¼Œå®šæ€§åˆ†æäº†ä¸€äº›ä¾‹å­ï¼Œæ˜¯æ²¡é—®é¢˜çš„ã€‚ç°åœ¨å°±æ˜¯æäº¤åˆ°open llmä¸Šäº†ï¼Œçœ‹çœ‹æ•ˆæœå·®åˆ«å¤§ä¸å¤§ã€‚åˆ°æ—¶å€™æœ‰ç»“è®ºäº†å‘Šè¯‰å¤§å®¶ã€‚ï¼ˆæ²¡æœ‰é‡åŒ–è¯„ä¼°ï¼Œopen llm lbæµ‹çš„å¤ªæ…¢äº†ï¼‰ï¼Œçº¿ä¸‹æµ‹äº†ä¸€äº›æ•ˆæœä¹Ÿæ˜¯å¯ä»¥çš„ã€‚å¦å¤–promptçš„å½±å“åœ¨sftä¹‹åå¯ä»¥å¿½å¾‹ä¸è®¡ï¼Œä¸åŒçš„æç¤ºå¯¹åæœŸæ¨¡å‹æ¨ç†å‡ ä¹ä¸å½±å“
- ï¼ˆ5ï¼‰ğŸš©ç»§ç»­å¾®è°ƒï¼ˆcontinue sftï¼‰ï¼šç¬¬ä¸€æ¬¡è·‘çš„æ˜¯å¤šè½®å¯¹è¯çš„æ•°æ®å’Œä¸€äº›alpaca ç±»ä¼¼çš„æ•°æ®ï¼Œè¿™æ¬¡æŒ‰ç…§ä¸€äº›é…æ¯”ç»§ç»­è·‘532kçš„å¤šæ ·æ€§æ•°æ®ï¼Œå‘ç°æ•ˆæœæ˜¯å¯ä»¥å åŠ çš„ï¼Œå¦å¤–ä¹‹å‰è®­ç»ƒçš„æ•ˆæœè¿˜å­˜åœ¨ï¼Œ
- ï¼ˆ6ï¼‰ğŸš©å‘ç°åœ¨ä¸­æ–‡é¢„è®­ç»ƒå’Œsftä¹‹åï¼Œç„¶åç”¨ä¸€äº›è‹±æ–‡çš„æŒ‡ä»¤æ•°æ®é›†èƒ½å¢å¼ºæ¨¡å‹çš„æŒ‡ä»¤å¯¹é½èƒ½åŠ›ã€‚

### 11 æ¨¡å‹sftä¹‹å ä¼šå‡ºç°å¾ªç¯è¾“å‡ºçš„ç°è±¡
![issue11.png](assets%2Fissue11.png)
![issue11_1.png](assets/issue11_1.png)

### 12 OpenSSL 3.0's legacy provider failed to load.
```text
RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):
OpenSSL 3.0's legacy provider failed to load. This is a fatal error by default, but cryptography supports running without legacy algorithms by setting the environment variable CRYPTOGRAPHY_OPENSSL_NO_LEGACY. If you did not expect this error,
 you have likely made a mistake with your OpenSSL configuration
```
ä¿®æ”¹æ–¹å¼ï¼š
åœ¨è™šæ‹Ÿç¯å¢ƒä¸‹ç›´æ¥æ‰§è¡Œï¼šexport CRYPTOGRAPHY_OPENSSL_NO_LEGACY=1
### 13 `flash_attn_unpadded_qkvpacked_func`ä¸èƒ½å¯¼å…¥

```text
ImportError: cannot import name 'flash_attn_unpadded_qkvpacked_func'
 from 'flash_attn.flash_attn_interface' (/data/searchgpt/anaconda3/envs/opencompass/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py)

```
https://github.com/Dao-AILab/flash-attention
```text
## Upgrading from FlashAttention (1.x) to FlashAttention-2

These functions have been renamed:
- `flash_attn_unpadded_func` -> `flash_attn_varlen_func`
- `flash_attn_unpadded_qkvpacked_func` -> `flash_attn_varlen_qkvpacked_func`
- `flash_attn_unpadded_kvpacked_func` -> `flash_attn_varlen_kvpacked_func`

```

### 14 Some NCCL operations have failed or timed out.
```text
[E ProcessGroupNCCL.cpp:460] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:455] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:460] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:455] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:460] To avoid data inconsistency, we are taking the entire process down.
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 76061 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 76064 closing signal SIGTERM
```


### 15 å¤§æ¨¡å‹å¾®è°ƒåå¯èƒ½å‡ºç°çš„ç»å…¸Bad Case
- ç”Ÿæˆæ–‡æœ¬æˆ›ç„¶è€Œæ­¢
```text

ç»¼ä¸Šæ‰€è¿°,å„æ–¹å¯¹é¦™æ¸¯ä¿ƒè¿›è‚¡ç¥¨å¸‚åœºæµåŠ¨æ€§ä¸“è´£å°ç»„æˆç«‹æŒä¸åŒçš„çœ‹æ³•,ä½†æ™®éè®¤ä¸ºè¿™
```
- æ¨¡å‹é‡å¤ç”Ÿæˆæ•ˆæœå·®å¼‚æ¯”è¾ƒå¤§ï¼Œç”šè‡³å¤šæ¬¡é‡å¤ç”Ÿæˆä¹‹åæ•ˆæœè¶Šæ¥è¶Šå·®
